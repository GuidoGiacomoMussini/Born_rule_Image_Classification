{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm as progress_bar\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from bornrule import BornClassifier\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def prediction_function(classifier_dict, classifier_, histogram_train, y_train, histogram_test, y_test, TFIDF=False):\n",
    "#    # Applicare TF-IDF\n",
    "#    if TFIDF:\n",
    "#        tfidf = TfidfTransformer()\n",
    "#        histogram_train = tfidf.fit_transform(histogram_train).toarray()\n",
    "#        histogram_test = tfidf.transform(histogram_test).toarray()\n",
    "#\n",
    "#    classifier = classifier_dict[classifier_]\n",
    "#    start = time.time()\n",
    "#    classifier.fit(histogram_train, y_train)\n",
    "#    y_pred = classifier.predict(histogram_test)\n",
    "#    end = time.time()-start\n",
    "#    results = {'y_obs': y_test, 'y_pred': y_pred}\n",
    "#    return results, end\n",
    "#\n",
    "#\n",
    "#def load_and_classify(classifier_dict, classifier_, file_path, TFIDF = False):\n",
    "#    # Estrazione dei parametri dal nome del file\n",
    "#    file_name = os.path.basename(file_path)\n",
    "#    match = re.match(r'(\\w+)_(\\w+)_(\\w+)_(\\w+)\\.pkl', file_name)\n",
    "#    if match:\n",
    "#        dataset = match.group(1)\n",
    "#        extractor_name = match.group(2)\n",
    "#        distance_metric = match.group(3)\n",
    "#        k = int(match.group(4))\n",
    "#    else:\n",
    "#        raise ValueError(\"Nome del file non conforme al formato previsto.\")\n",
    "#    \n",
    "#    with open(file_path, 'rb') as f:\n",
    "#        data = pickle.load(f)\n",
    "#    \n",
    "#    histogram_train = np.array(data['histograms_train'])\n",
    "#    y_train = np.array(data['y_train'])\n",
    "#    histogram_test = np.array(data['histograms_test'])\n",
    "#    y_test = np.array(data['y_test'])\n",
    "#\n",
    "#    results, comp_time = prediction_function(classifier_dict, classifier_, histogram_train, y_train, histogram_test, y_test, TFIDF)\n",
    "#    f1 = f1_score(results['y_obs'], results['y_pred'], average='weighted')\n",
    "#    \n",
    "#    tuning_results = []\n",
    "#    tuning_results.append({\n",
    "#        'Params': {'classifier': classifier_, 'dataset':dataset, 'extractor': extractor_name, 'distance_metric': distance_metric, 'k': k, 'tfidf': TFIDF},\n",
    "#        'F1_Score': f1 * 100,\n",
    "#        'Comp_time': comp_time\n",
    "#    })\n",
    "#    \n",
    "#    return tuning_results\n",
    "#\n",
    "#\n",
    "#def results_to_dataframe(results_dict):\n",
    "#    records = []\n",
    "#    for sublist in results_dict:\n",
    "#        for result in sublist:\n",
    "#            params = result['Params']\n",
    "#            classifier = params.get('classifier')\n",
    "#            dataset = params.get('dataset')\n",
    "#            extractor = params.get('extractor')\n",
    "#            distance_metric = params.get('distance_metric')\n",
    "#            k = params.get('k')\n",
    "#            tfidf = params.get('tfidf')\n",
    "#            f1_score = result.get('F1_Score')\n",
    "#            computational_time = result.get('Comp_time')\n",
    "#            \n",
    "#            records.append((dataset, classifier, extractor, distance_metric, k, round(f1_score, 3), round(computational_time, 3), tfidf))\n",
    "#\n",
    "#    df = pd.DataFrame(records, columns=['Dataset', 'Classifier', 'Extractor', 'Distance_Metric', 'K', 'F1_Score(%)', 'Computational_time(s)', 'tfidf'])\n",
    "#    df = df.sort_values(by='F1_Score(%)', ascending=False)\n",
    "#    \n",
    "#    return df\n",
    "\n",
    "\n",
    "\n",
    "def cross_val_prediction_function(classifier_dict, classifier_, histogram_data, y_data, n_splits=5, TFIDF=False):\n",
    "    # Applicare TF-IDF\n",
    "    if TFIDF:\n",
    "        tfidf = TfidfTransformer()\n",
    "        histogram_data = tfidf.fit_transform(histogram_data).toarray()\n",
    "\n",
    "    classifier = classifier_dict[classifier_]\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    f1_scores = []\n",
    "    computation_times = []\n",
    "\n",
    "    for train_index, test_index in skf.split(histogram_data, y_data):\n",
    "        histogram_train, histogram_test = histogram_data[train_index], histogram_data[test_index]\n",
    "        y_train, y_test = y_data[train_index], y_data[test_index]\n",
    "        \n",
    "        start = time.time()\n",
    "        classifier.fit(histogram_train, y_train)\n",
    "        y_pred = classifier.predict(histogram_test)\n",
    "        end = time.time() - start\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        f1_scores.append(f1)\n",
    "        computation_times.append(end)\n",
    "    \n",
    "    avg_f1_score = np.mean(f1_scores)\n",
    "    avg_computation_time = np.mean(computation_times)\n",
    "    results = {'y_obs': y_test, 'y_pred': y_pred}\n",
    "    \n",
    "    return results, avg_f1_score, avg_computation_time\n",
    "\n",
    "\n",
    "def load_and_classify(classifier_dict, classifier_, file_path, n_splits=5, TFIDF=False):\n",
    "    # Estrazione dei parametri dal nome del file\n",
    "    file_name = os.path.basename(file_path)\n",
    "    match = re.match(r'(\\w+)_(\\w+)_(\\w+)_(\\w+)\\.pkl', file_name)\n",
    "    if match:\n",
    "        dataset = match.group(1)\n",
    "        extractor_name = match.group(2)\n",
    "        distance_metric = match.group(3)\n",
    "        k = int(match.group(4))\n",
    "    else:\n",
    "        raise ValueError(\"Nome del file non conforme al formato previsto.\")\n",
    "    \n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    histogram_train = np.array(data['histograms_train'])\n",
    "    y_train = np.array(data['y_train'])\n",
    "    histogram_test = np.array(data['histograms_test'])\n",
    "    y_test = np.array(data['y_test'])\n",
    "\n",
    "    histogram_data = np.concatenate((histogram_train, histogram_test), axis=0)\n",
    "    y_data = np.concatenate((y_train, y_test), axis=0).flatten()\n",
    "\n",
    "    \n",
    "    results, avg_f1_score, avg_computation_time = cross_val_prediction_function(classifier_dict, classifier_, histogram_data, y_data, n_splits, TFIDF)\n",
    "    \n",
    "    tuning_results = []\n",
    "    tuning_results.append({\n",
    "        'Params': {'classifier': classifier_, 'dataset': dataset, 'extractor': extractor_name, 'distance_metric': distance_metric, 'k': k, 'tfidf': TFIDF},\n",
    "        'F1_Score': avg_f1_score * 100,\n",
    "        'Comp_time': avg_computation_time\n",
    "    })\n",
    "    \n",
    "    return tuning_results\n",
    "\n",
    "\n",
    "def results_to_dataframe(results_dict):\n",
    "    records = []\n",
    "    for sublist in results_dict:\n",
    "        for result in sublist:\n",
    "            params = result['Params']\n",
    "            classifier = params.get('classifier')\n",
    "            dataset = params.get('dataset')\n",
    "            extractor = params.get('extractor')\n",
    "            distance_metric = params.get('distance_metric')\n",
    "            k = params.get('k')\n",
    "            tfidf = params.get('tfidf')\n",
    "            f1_score = result.get('F1_Score')\n",
    "            computational_time = result.get('Comp_time')\n",
    "            \n",
    "            records.append((dataset, classifier, extractor, distance_metric, k, round(f1_score, 3), round(computational_time, 3), tfidf))\n",
    "\n",
    "    df = pd.DataFrame(records, columns=['Dataset', 'Classifier', 'Extractor', 'Distance_Metric', 'K', 'F1_Score(%)', 'Computational_time(s)', 'tfidf'])\n",
    "    df = df.sort_values(by='F1_Score(%)', ascending=False)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Histograms_repository'\n",
    "file_names = [f\"{file_path}/{f}\" for f in os.listdir(file_path) if os.path.isfile(os.path.join(file_path, f))]\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"KNeighbors\": KNeighborsClassifier(),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"BORN(0.5,1,1)\": BornClassifier(0.5,1,1),\n",
    "    \"BORN(0.5,1,0)\": BornClassifier(0.5,1,0),\n",
    "    \"BORN(1,0,0)\": BornClassifier(1,0,0),\n",
    "    \"BORN(1,0,1)\": BornClassifier(1,0,1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = []\n",
    "for file in progress_bar(file_names):\n",
    "    for classifier in classifiers:\n",
    "        results_dict.append(load_and_classify(classifiers, classifier, file, TFIDF=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results_to_dataframe(results_dict)\n",
    "df.to_csv(\"cv_results_all_configurations_cifar_imnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Extractor</th>\n",
       "      <th>Distance_Metric</th>\n",
       "      <th>K</th>\n",
       "      <th>F1_Score(%)</th>\n",
       "      <th>Computational_time(s)</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>IMAGENET</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SIFT</td>\n",
       "      <td>cosine</td>\n",
       "      <td>5000</td>\n",
       "      <td>52.712</td>\n",
       "      <td>10.913</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>IMAGENET</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SIFT</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>5000</td>\n",
       "      <td>52.572</td>\n",
       "      <td>9.809</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>IMAGENET</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SIFT</td>\n",
       "      <td>cosine</td>\n",
       "      <td>2500</td>\n",
       "      <td>52.202</td>\n",
       "      <td>5.172</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>IMAGENET</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SIFT</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>2500</td>\n",
       "      <td>51.645</td>\n",
       "      <td>5.455</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>IMAGENET</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SIFT</td>\n",
       "      <td>cosine</td>\n",
       "      <td>100</td>\n",
       "      <td>49.635</td>\n",
       "      <td>0.525</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>IMAGENET</td>\n",
       "      <td>BORN(0.5,1,1)</td>\n",
       "      <td>ORB</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>10</td>\n",
       "      <td>3.508</td>\n",
       "      <td>0.007</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>IMAGENET</td>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>ORB</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>2500</td>\n",
       "      <td>3.484</td>\n",
       "      <td>1.726</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>IMAGENET</td>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>ORB</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>5000</td>\n",
       "      <td>3.321</td>\n",
       "      <td>3.450</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>IMAGENET</td>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>ORB</td>\n",
       "      <td>cosine</td>\n",
       "      <td>2500</td>\n",
       "      <td>3.035</td>\n",
       "      <td>1.766</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>IMAGENET</td>\n",
       "      <td>BORN(0.5,1,1)</td>\n",
       "      <td>ORB</td>\n",
       "      <td>cosine</td>\n",
       "      <td>10</td>\n",
       "      <td>2.486</td>\n",
       "      <td>0.006</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dataset          Classifier Extractor Distance_Metric     K  \\\n",
       "307  IMAGENET  LogisticRegression      SIFT          cosine  5000   \n",
       "352  IMAGENET  LogisticRegression      SIFT       euclidean  5000   \n",
       "298  IMAGENET  LogisticRegression      SIFT          cosine  2500   \n",
       "343  IMAGENET  LogisticRegression      SIFT       euclidean  2500   \n",
       "280  IMAGENET  LogisticRegression      SIFT          cosine   100   \n",
       "..        ...                 ...       ...             ...   ...   \n",
       "230  IMAGENET       BORN(0.5,1,1)       ORB       euclidean    10   \n",
       "255  IMAGENET          KNeighbors       ORB       euclidean  2500   \n",
       "264  IMAGENET          KNeighbors       ORB       euclidean  5000   \n",
       "210  IMAGENET          KNeighbors       ORB          cosine  2500   \n",
       "185  IMAGENET       BORN(0.5,1,1)       ORB          cosine    10   \n",
       "\n",
       "     F1_Score(%)  Computational_time(s)  tfidf  \n",
       "307       52.712                 10.913  False  \n",
       "352       52.572                  9.809  False  \n",
       "298       52.202                  5.172  False  \n",
       "343       51.645                  5.455  False  \n",
       "280       49.635                  0.525  False  \n",
       "..           ...                    ...    ...  \n",
       "230        3.508                  0.007  False  \n",
       "255        3.484                  1.726  False  \n",
       "264        3.321                  3.450  False  \n",
       "210        3.035                  1.766  False  \n",
       "185        2.486                  0.006  False  \n",
       "\n",
       "[360 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### result analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('File_with_results/cifar_imagenet_pipeline_results')  \n",
    "df = df.rename(columns={'Dataset': 'temp_col', 'Classifier': 'Dataset'})\n",
    "df = df.rename(columns={'temp_col': 'Classifier'})\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "columns = list(df.columns)\n",
    "col1_index = columns.index('Dataset')\n",
    "col2_index = columns.index('Classifier')\n",
    "columns[col1_index], columns[col2_index] = columns[col2_index], columns[col1_index]\n",
    "df = df[columns]\n",
    "df = df[df['Classifier'].str.startswith('BORN')].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['match'] = [f\"{df.Dataset[i]}_{df.Classifier[i]}_{df.Extractor[i]}_{df.Distance_Metric[i]}_{df.K[i]}\" for i in range(len(df))]\n",
    "df = df[['match', 'F1_Score(%)']]\n",
    "\n",
    "df_tfidf['match'] = [f\"{df_tfidf.Dataset[i]}_{df_tfidf.Classifier[i]}_{df_tfidf.Extractor[i]}_{df_tfidf.Distance_Metric[i]}_{df_tfidf.K[i]}\" for i in range(len(df_tfidf))]\n",
    "df_tfidf = df_tfidf[['match', 'F1_Score(%)']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df, df_tfidf, on='match', suffixes=('_histograms', '_tfidf'))\n",
    "df_merged[['dataset', 'classifier', 'extractor', 'distance_metric', 'K']] = df_merged['match'].str.split('_', expand=True)\n",
    "df_merged = df_merged[['dataset', 'classifier', 'extractor', 'distance_metric', 'K', 'F1_Score(%)_histograms', 'F1_Score(%)_tfidf']]\n",
    "df_merged['difference'] = df_merged['F1_Score(%)_histograms'] - df_merged['F1_Score(%)_tfidf']\n",
    "df_merged = df_merged.rename(columns={'F1_Score(%)_histograms': 'f1_hist', 'F1_Score(%)_tfidf': 'f1_tfidf'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged = df_merged[(df_merged.dataset =='IMAGENET')]\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged = df_merged[(df_merged.extractor =='SIFT') & (df_merged.distance_metric == 'euclidean') & (df_merged.K == '2500')].reset_index(drop=True)\n",
    "# df_merged\n",
    "# df_merged = df_merged[df_merged.difference <0].reset_index(drop=True)\n",
    "# df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Impostazioni del grafico\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Impostare la larghezza delle barre\n",
    "bar_width = 0.35\n",
    "\n",
    "# Indici delle barre\n",
    "index = range(len(df_merged))\n",
    "\n",
    "# Barre per 'F1_score(%)_original'\n",
    "plt.bar(index, df_merged['f1_hist'], bar_width, label='Original')\n",
    "\n",
    "# Barre per 'F1_score(%)_tfidf'\n",
    "plt.bar([i + bar_width for i in index], df_merged['f1_tfidf'], bar_width, label='TF-IDF')\n",
    "\n",
    "# Aggiungere le etichette e il titolo\n",
    "plt.xlabel('Match')\n",
    "plt.ylabel('F1 Score (%)')\n",
    "plt.title('Confronto degli F1 Score (%) Original e TF-IDF')\n",
    "plt.xticks([i + bar_width / 2 for i in index])\n",
    "plt.legend()\n",
    "\n",
    "# Mostrare il grafico\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
